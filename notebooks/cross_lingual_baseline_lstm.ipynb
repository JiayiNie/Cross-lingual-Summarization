{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8db7b08df4464832b0bdac0579e82376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3be418530639476889a4e117759b3dc0",
              "IPY_MODEL_52f59919f17d4e09a98b18a34f3fa06f",
              "IPY_MODEL_8dbc5d52b4bf46b0a8f8b88b72525cac"
            ],
            "layout": "IPY_MODEL_3e44da9639ce4e7abba47ba8db44ab2f"
          }
        },
        "3be418530639476889a4e117759b3dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c6d07aa4fd4219a860f0463043b3e6",
            "placeholder": "​",
            "style": "IPY_MODEL_cd5cdf7ab8c842e58c95f5c22015a45b",
            "value": "100%"
          }
        },
        "52f59919f17d4e09a98b18a34f3fa06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d726c0db7814f3a8ac204844a2b4bf5",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffb34db0695344a791845053ea8340d3",
            "value": 50000
          }
        },
        "8dbc5d52b4bf46b0a8f8b88b72525cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62c294b0b0c4b0c8df56e306cc09fad",
            "placeholder": "​",
            "style": "IPY_MODEL_88b4e1b908904bafb059cdb39236eacb",
            "value": " 50000/50000 [01:15&lt;00:00, 838.73it/s]"
          }
        },
        "3e44da9639ce4e7abba47ba8db44ab2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c6d07aa4fd4219a860f0463043b3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5cdf7ab8c842e58c95f5c22015a45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d726c0db7814f3a8ac204844a2b4bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb34db0695344a791845053ea8340d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b62c294b0b0c4b0c8df56e306cc09fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b4e1b908904bafb059cdb39236eacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeNXkas2-rCl"
      },
      "source": [
        "import pickle \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline\n",
        "# from gensim import corpora, models, similarities, matutils\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle \n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCymvVz4PR_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbe5885-1313-48ed-eea6-e87dd9d4a6d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data pre-processing \n",
        "load files\n",
        "\n",
        "tokenization\n",
        "\n",
        "build vocabularies"
      ],
      "metadata": {
        "id": "EXlRWZvn7jCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('fr_text_preprocessed_50000.txt', encoding='utf-8') as file1:\n",
        "    articles = file1.readlines()\n",
        "with open('en_sum_preprocessed_50000.txt', encoding='utf-8') as file2:\n",
        "    sums = file2.readlines()\n"
      ],
      "metadata": {
        "id": "lLa5UzHgve-l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbmkZULj_Q7r",
        "outputId": "7a43015e-15d6-43a7-e8ed-14ed0a0d2d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"summary #\",i+1)\n",
        "    print(articles[i])\n",
        "    print(sums[i])\n",
        "    print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary # 1\n",
            "jean-jacques schuhl gilles leroy christian gailly yasmina khadra james ellroy amos naipaul rentree janvier sannonce sous meilleurs auspices force constater 491 romans contre 558 2009 tendance baisse enregistree lautomne saccentue principale victime cette glaciation litterature etrangere enregistre recul 167 romans contre 211 lan dernier plus bas niveau depuis 2001 peut-etre doit-on voir contrecoup laugmentation droits dauteur traduction aussi fait organisateurs salon livre choisi celebrer trente ans manifestation invitant non pays ecrivains francais etrangers litterature francaise cote marque leger flechissement 324 livres contre 347 lan passe premiers romans apres automne demi-teinte repartent hausse titres contre 2009 loin leffervescence septembre tension prix cette rentree hivernale placee sous signe decrue nen offre moins programme belle qualite ainsi chez gallimard retour jean-jacques schuhl entree fantomes dix ans apres goncourt ingrid caven deja annonce comme lun evenements rentree tout comme nouveau roman patrick modiano prevu mars autres tetes daffiche philippe sollers discours parfait troisieme tome articles chroniques entretiens richard millet propose recit roman liban tient grande place camille laurens narre romance nerveuse rencontre dune romanciere dun paparazzi encore philippe djian dont nouveau livre incidences paraitra fevrier cote filiales gallimard notons presence dun autre goncourt gilles leroy propose mercure france zola jackson chez verticales arnaud cathrine poursuit exploration roman-choral journal intime benjamin lorca tandis celine minard chez denoel propose olimpia portrait sulfureux belle-soeur pape innocent enfin chez pol lessai marie darrieussecq rapport police accusation plagiat autres modes surveillance fiction pourraient bien susciter quelques polemiques face cette escouade grasset nest reste publie dernier roman jacques chessex decede octobre dernier crane sade chesseien diable aussi troisieme chronique regne nicolas ier patrick rambaud lemouvant roman premier amour\n",
            "\n",
            "jean-jacques schuhl , gilles leroy , christian gailly , yasmina khadra , james ellroy , amos oz , v. s. naipaul... the start of the new school year in january is starting off under the best auspices .\n",
            "\n",
            "\n",
            "summary # 2\n",
            "semaine apres lattaque terroriste manquee bord dun vol destination etats-unis jeune nigerian sejourne yemen gordon brown appele vendredi reunion internationale yemen lutte contre terrorisme janvier londres cette reunion doit tenir parallele conference internationale lafghanistan deja prevue londres meme date selon downing street projet deja recu fort soutien maison blanche lunion europeenne grande-bretagne sattachera prochains jours obtenir lappui larabie saoudite pays golfe tentative jeune nigerian omar farouk abdulmutallab faire exploser jour noel avion ligne americain provenance damsterdam sappretait atterrir detroit souligne menace terroriste toujours tres presente huit ans apres evenements septembre 2001 rappele plus tot vendredi article premier ministre britannique jeune homme ans affirme avoir ete entraine yemen al-qaida selon responsables americains cites medias ministere yemenite affaires etrangeres confirme nigerian trouvait encore debut decembre yemen peu avant lattentat quil tente perpetrer reunion devrait chercher encourager coordonner laide internationale yemen renforcer capacite gouvernement controle lensemble territoire contribuer developpement economique zones plus propices radicalisation militants selon downing street vise egalement identifier besoins pays afin celui-ci puisse lutter contre terrorisme deboucher engagements etats participants renforcer larmee yemenite coordonner efforts contre terrorisme region\n",
            "\n",
            "this request comes a week after the failed terrorist attack on board a flight to the united states by a young nigerian who had stayed in yemen .\n",
            "\n",
            "\n",
            "summary # 3\n",
            "juge americain rejete jeudi decembre accusations portees contre cinq employes blackwater plus grande entreprise privee securite utilisee etats-unis irak accuses davoir ouvert feu bagdad foule tue quatorze irakiens 2007 lors dune mission departement detat decision aussitot suscite lindignation irak jai ete vraiment stupefaite decision jattends lambassade americaine copie decision juge ainsi affirme ministre droits lhomme irakienne wejdane mikhail sest passe ete tres mauvais car tant personnes innocentes mortes jeunes etudiants tues quelquun aimait tirer gens non armes juge federal ricardo urbina argue decision laccusation viole droits accuses utilisant temoignages livres alors agents securite etaient proteges limmunite conferait gouvernement americain tous irakiens vont etre mecontents tellement travail fait poursuivre gens justice comprends decision juge explique mme mikhail selon ministre temoignages presentes etaient suffisants renvoyer cinq agents devant justice americaine lun agents raconte setait passe place nousour comment tue gens innocents trouvaient juste voiture sans aucune arme insiste-t-elle contrecoup cet incident provoque colere irakiens nont cesse daccuser agents securite etrangers davoir detente trop facile dagir sans retenue toute impunite apres cet incident gouvernement retire licence dexploitation blackwater dont contrats selevaient centaines millions dollars debut mars patron fondateur societe americaine securite nouveau nom blackwater erik prince annonce demission apres perte contrat irak leurs convois sillonnant bagdad vive allure leurs gardes ouvrant feu lair faire passage embouteillages helicopteres survolant sans cesse ciel bagdad blackwater etait devenu irakiens symbole agissements controverses societes privees porte-parole gouvernement irakien assure lenquete menee autorites irakiennes indiquait sans lombre dun doute gardes etaient responsables mort civils irakiens commandant forces americaines irak ray odierno dit craindre decision juge americain repercussions lensemble societes privees crains cest quil contrecoup contre societes\n",
            "\n",
            "a us judge on thursday dismissed charges against five employees of the security company , accused of opening fire in baghdad on the crowd and killing fourteen iraqis in 2007 .\n",
            "\n",
            "\n",
            "summary # 4\n",
            "attentat fait moins morts plusieurs dizaines blesses vendredi 1er cinq personnes decedees pendant nuit lhopital porte bilan morts janvier pakistan selon nouveau bilan fourni samedi police kamikaze fait exploser bombe milieu dun terrain volley-ball declare chef police locale precise kamikaze precipite voiture chargee dexplosifs terrain autour duquel villageois etaient rassembles regarder match lexplosion provoque leffondrement dune maison situee proximite dou ete extraites plusieurs victimes femmes enfants lattentat lieu shah hasan khan village district bannu voisin zones tribales frontalieres lafghanistan larmee pakistanaise combat actuellement talibans allies al-qaida cette fin dannee pays victime dun regain violence lundi attentat-suicide karachi revendique talibans fait quarante-trois morts reunion dun comite local anti-talibans tenait mosquee situee juste cote terrain volley-ball lors lattentat indique mushtaq marwat membre comite paix chaine television locale geo soudain enorme explosion sortis morts blesses partout a-t-il raconte estimant bilan devrait salourdir combattre menace terroriste jusqu elimination totale premier ministre youssouf raza gilani condamne lattentat affirmant communique tels actes terroristes peuvent affaiblir resolution gouvernement combattre menace terroriste jusqu elimination totale nord-ouest pakistan cible privilegiee vague dattentats islamistes secoue pakistan fait plus deux mille huit cents morts depuis pres deux ans demi cette sanglante serie sest acceleree depuis octobre lorsque larmee lance offensive terrestre contre talibans waziristan sud fief mouvement talibans pakistanais ttp allie al-qaida ttp allies denoncent lalignement pakistan guerre contre terrorisme menee etats-unis region consideres comme principaux auteurs attentats perpetres depuis deux ans demi ttp egalement revendique attentat contre procession chiite fait quarante-trois morts lundi dernier karachi sud pakistan semble demontrer capacite nuisance setend bien dela nord-ouest\n",
            "\n",
            "a suicide bomber detonated his car bomb on friday in the middle of a volleyball court .\n",
            "\n",
            "\n",
            "summary # 5\n",
            "cinq personnes mortes treize autres ete blessees nimes gard incendie sest declenche vendredi 1er janvier petit matin feu dont ignore lorigine linstant pris sixieme dernier etage dun immeuble larrivee pompiers trois personnes etaient decedees appartement deux autres appartement voisin intoxication explique i-tele directeur cabinet prefet gard denombre egalement treize blesses dont trois graves personne coma ete transferee marseille a-t-il ajoute secours ete prevenus vers heures matin lincendie deja bien demarre a-t-il explique france info precise victimes trois adultes deux enfants lorigine lincendie indeterminee priori accidentelle declare procureur adjoint republique nimes cite europe\n",
            "\n",
            "five people died , and thirteen others were injured in nimes , in the gard , in a fire which broke out on friday january 1 in the early morning .\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the number of training sentences used to train\n",
        "training_examples = len(articles)\n",
        "\n",
        "en_words = Counter()\n",
        "fr_words = Counter()\n",
        "en_inputs = []\n",
        "fr_inputs = []\n",
        "\n",
        "# Tokenizing the English and French sentences and creating our word banks for both languages\n",
        "for i in tqdm_notebook(range(training_examples)):\n",
        "    en_tokens = word_tokenize(sums[i])\n",
        "    fr_tokens = word_tokenize(articles[i])\n",
        "    if len(en_tokens)==0 or len(fr_tokens)==0:\n",
        "        continue\n",
        "    for token in en_tokens:\n",
        "        en_words.update([token.lower()])\n",
        "    en_inputs.append([token.lower() for token in en_tokens] + ['_EOS'])\n",
        "    for token in fr_tokens:\n",
        "        fr_words.update([token.lower()])\n",
        "    fr_inputs.append([token.lower() for token in fr_tokens] + ['_EOS'])\n",
        "\n",
        "#Assigning an index to each word token, including the Start Of String(SOS), End Of String(EOS) and Unknown(UNK) tokens\n",
        "en_words = ['_SOS','_EOS','_UNK'] + sorted(en_words,key=en_words.get,reverse=True)\n",
        "en_w2i = {o:i for i,o in enumerate(en_words)}\n",
        "en_i2w = {i:o for i,o in enumerate(en_words)}\n",
        "fr_words = ['_SOS','_EOS','_UNK'] + sorted(fr_words,key=fr_words.get,reverse=True)\n",
        "fr_w2i = {o:i for i,o in enumerate(fr_words)}\n",
        "fr_i2w = {i:o for i,o in enumerate(fr_words)}\n",
        "\n",
        "#Converting our English and French sentences to their token indexes\n",
        "for i in range(len(en_inputs)):\n",
        "    en_sentence = en_inputs[i]\n",
        "    fr_sentence = fr_inputs[i]\n",
        "    en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
        "    fr_inputs[i] = [fr_w2i[word] for word in fr_sentence]\n"
      ],
      "metadata": {
        "id": "qB35ZVmjPffD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "8db7b08df4464832b0bdac0579e82376",
            "3be418530639476889a4e117759b3dc0",
            "52f59919f17d4e09a98b18a34f3fa06f",
            "8dbc5d52b4bf46b0a8f8b88b72525cac",
            "3e44da9639ce4e7abba47ba8db44ab2f",
            "e4c6d07aa4fd4219a860f0463043b3e6",
            "cd5cdf7ab8c842e58c95f5c22015a45b",
            "0d726c0db7814f3a8ac204844a2b4bf5",
            "ffb34db0695344a791845053ea8340d3",
            "b62c294b0b0c4b0c8df56e306cc09fad",
            "88b4e1b908904bafb059cdb39236eacb"
          ]
        },
        "outputId": "9f9ec2be-3e64-4854-cd0e-0b5407473187"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-14b74f61c9e7>:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm_notebook(range(training_examples)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8db7b08df4464832b0bdac0579e82376"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#store english and french vocabularies \n",
        "with open('en_word2index.pkl', 'wb') as f:\n",
        "    pickle.dump(en_w2i, f)\n",
        "        \n",
        "with open('en_index2word.pkl', 'wb') as f:\n",
        "    pickle.dump(en_i2w, f)\n",
        "\n",
        "with open('fr_word2index.pkl', 'wb') as f:\n",
        "    pickle.dump(fr_w2i, f)\n",
        "\n",
        "with open('fr_index2word.pkl', 'wb') as f:\n",
        "    pickle.dump(fr_i2w, f)\n"
      ],
      "metadata": {
        "id": "Z7Z9LRJ2sqpK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder"
      ],
      "metadata": {
        "id": "833dGkU00CaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        #Embed input words\n",
        "        embedded = self.embedding(inputs)\n",
        "        #Pass the embedded word vectors into LSTM and return all outputs\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size=1):\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
        "                torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))\n"
      ],
      "metadata": {
        "id": "9x74wMa-zUO0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "UvOYqFSl0GjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, attention, n_layers=1, drop_prob=0.1):\n",
        "        super(LuongDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "        #Our Attention Mechanism is defined in a separate class\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.drop_prob)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "        self.classifier = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "    \n",
        "    def forward(self, inputs, hidden, encoder_outputs):\n",
        "        #Embed input words\n",
        "        embedded = self.embedding(inputs).view(1,1,-1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        #Passing previous output word (embedded) and hidden state into LSTM cell\n",
        "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
        "\n",
        "        #Calculating Alignment Scores - see Attention class for the forward pass function\n",
        "        alignment_scores = self.attention(hidden[0], encoder_outputs)\n",
        "        #Softmaxing alignment scores to obtain Attention weights\n",
        "        attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
        "\n",
        "        #Multiplying Attention weights with encoder outputs to get context vector\n",
        "        context_vector = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs)\n",
        "\n",
        "        #Concatenating output from LSTM with context vector\n",
        "        output = torch.cat((lstm_out, context_vector),-1)\n",
        "        #Pass concatenated vector through Linear layer acting as a Classifier\n",
        "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "YrNC0oKC0PON"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size, method=\"dot\"):\n",
        "        super(Attention, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        #Defining the layers/weights required depending on alignment scoring method\n",
        "        if method == \"general\":\n",
        "            self.fc = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        elif method == \"concat\":\n",
        "            self.fc = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "            self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
        "  \n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        if self.method == \"dot\":\n",
        "          #For the dot scoring method, no weights or linear layers are involved\n",
        "          return encoder_outputs.bmm(decoder_hidden.view(1,-1,1)).squeeze(-1)\n",
        "    \n",
        "        elif self.method == \"general\":\n",
        "            #For general scoring, decoder hidden state is passed through linear layers to introduce a weight matrix\n",
        "            out = self.fc(decoder_hidden)\n",
        "            return encoder_outputs.bmm(out.view(1,-1,1)).squeeze(-1)\n",
        "\n",
        "        elif self.method == \"concat\":\n",
        "            #For concat scoring, decoder hidden state and encoder outputs are concatenated first\n",
        "            out = torch.tanh(self.fc(decoder_hidden+encoder_outputs))\n",
        "            return out.bmm(self.weight.unsqueeze(-1)).squeeze(-1)"
      ],
      "metadata": {
        "id": "vkLkxfTPzz-e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "lXVikACGyZhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512\n",
        "encoder = EncoderLSTM(len(fr_words), hidden_size).to(device)\n",
        "attn = Attention(hidden_size,\"concat\")\n",
        "decoder = LuongDecoder(hidden_size,len(en_words),attn).to(device)\n",
        "\n",
        "lr = 0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "NnBb4sDtPYa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "teacher_forcing_prob = 0.5\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    avg_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    with tqdm(fr_inputs, desc=f\"Epoch {epoch}/{EPOCHS}\") as pbar:\n",
        "        for i, sentence in enumerate(pbar):\n",
        "            loss = 0.\n",
        "            h = encoder.init_hidden()\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
        "            encoder_outputs, h = encoder(inp, h)\n",
        "\n",
        "            # First decoder input will be the SOS token\n",
        "            decoder_input = torch.tensor([en_w2i['_SOS']], device=device)\n",
        "            # First decoder hidden state will be last encoder hidden state\n",
        "            decoder_hidden = h\n",
        "            output = []\n",
        "            teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
        "\n",
        "            for ii in range(len(en_inputs[i])):\n",
        "                decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "                # Get the index value of the word with the highest score from the decoder output\n",
        "                top_value, top_index = decoder_output.topk(1)\n",
        "                if teacher_forcing:\n",
        "                    decoder_input = torch.tensor([en_inputs[i][ii]], device=device)\n",
        "                else:\n",
        "                    decoder_input = torch.tensor([top_index.item()], device=device)\n",
        "                output.append(top_index.item())\n",
        "                # Calculate the loss of the prediction against the actual word\n",
        "                loss += F.nll_loss(decoder_output.view(1, -1), torch.tensor([en_inputs[i][ii]], device=device))\n",
        "\n",
        "                # Calculate the number of correct predictions\n",
        "                if top_index.item() == en_inputs[i][ii]:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "            # print(output)\n",
        "            # print(fr_inputs[i])\n",
        "\n",
        "            loss = loss / len(en_inputs[i])\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            avg_loss += loss.item() / len(en_inputs)\n",
        "            \n",
        "            pbar.set_postfix(loss=loss.item(), accuracy=correct / total)\n",
        "        \n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch} loss: {avg_loss:.4f} | accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    # Save model after every epoch\n",
        "    torch.save({\"encoder\": encoder.state_dict(), \"decoder\": decoder.state_dict(), \"e_optimizer\": encoder_optimizer.state_dict(), \"d_optimizer\": decoder_optimizer.state_dict(), \"epoch\": epoch}, f\"model_epoch_{epoch}.pth\")\n"
      ],
      "metadata": {
        "id": "GE8hS72h0Yj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "RvuejzcKxUgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load dictionaries\n",
        "with open('en_word2index.pkl', 'rb') as f:\n",
        "    loaded_en_w2i = pickle.load(f)\n",
        "with open('en_index2word.pkl', 'rb') as f:\n",
        "    loaded_en_i2w = pickle.load(f)\n",
        "\n",
        "with open('fr_word2index.pkl', 'rb') as f:\n",
        "    loaded_fr_w2i = pickle.load(f)\n",
        "with open('fr_index2word.pkl', 'rb') as f:\n",
        "    loaded_fr_i2w = pickle.load(f)\n",
        "\n",
        "with open('fr_text_preprocessed_test1000.txt', encoding='utf-8') as file3:\n",
        "    test_articles = file3.readlines()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OHf9PRU6u2hx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en_inputs = []\n",
        "fr_inputs = []\n",
        "\n",
        "#Converting French testing articles to their token indexes\n",
        "for i in range(len(test_articles)):\n",
        "\n",
        "    #tokenize first:\n",
        "    fr_tokens = word_tokenize(test_articles[i])\n",
        "    fr_inputs.append([token.lower() for token in fr_tokens] + ['_EOS'])\n",
        "    \n",
        "    #word to index\n",
        "    fr_article= fr_inputs[i]\n",
        "    fr_inputs[i] = [loaded_fr_w2i[word] if word in loaded_fr_w2i else loaded_fr_w2i['_UNK'] for word in fr_article]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "32utCOJmDZHW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are \",len(fr_inputs), \"testing samples\")\n",
        "print(\"Visualize one article for testing: \" + \" \".join([loaded_fr_i2w[x] for x in fr_inputs[10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEX-mp2e9MLj",
        "outputId": "80424267-4e00-4cca-99cc-6f1738c62cb0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are  1000 testing samples\n",
            "Visualize one article for testing: separation pouvoirs notion plus celebree nen guere daussi confuse 1789 declaration droits lhomme citoyen notait article quune societe laquelle separation pouvoirs netait garantie point constitution deux siecles plus tard quasi-totalite constitutions adoptees pays lex-bloc sovietique reprenaient presque mot mot meme enonce faits nul pourtant jamais envisage trois pouvoirs executif judiciaire legislatif puisque cest deux quil sagissait puissent fonctionner facon vraiment autonome derriere terme separation cest fait plutot lidee dun equilibre dune balance pouvoirs lon envisagee paradoxe regimes moins democratiques entendu sappuyer xixe siecle lexpression separation pouvoirs _UNK exemple lindependance pouvoir executif mettre labri toute velleite controle parlementaire cela ete cas second empire france concentrons-nous present posant deux questions avons-nous besoin dune separation dun equilibre pouvoirs oui selon quelles modalites notons preambule vieille _UNK plus aucun sens toutes societes modernes partout quun seul pouvoir dirigeant pouvoir executif cest reviennent initiatives decisions essentielles pouvoir legislatif selon modalites differentes autres pays quune capacite limitee controler contraindre voire censurer lexecutif quant pouvoir judiciaire nexiste plus depuis longtemps tant tel notion navait sens lorsque systeme judiciaire participait lexercice volonte politique fonction legislative meme executive avant mette place etat administratif activite etant dorenavant contentieuse cest dautorite judiciaire quil convient parler terme separation pouvoirs selon lancienne _UNK donc plus consistance nen moins plus necessaire jamais contrecarrer tendance permanente pouvoir general executif sexercer sans contrepoids presenter comme seul legitime contre cette double pretention necessaire reformuler termes dune nouvelle architecture pouvoirs plus dune separation dune balance ceux-ci cest termes complication demultiplication distinction fonctions formes democratiques quil faut raisonner faut dabord demultiplier modes dexpression volonte generale pouvoir politique tire legitimite lelection celle-ci mele deux dimensions _EOS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved model\n",
        "model_path = \"model_epoch_5.pth\"\n",
        "\n",
        "# Load the saved model\n",
        "checkpoint = torch.load(model_path)\n",
        "\n",
        "# Extract the encoder and decoder state dictionaries from the loaded checkpoint\n",
        "encoder_state_dict = checkpoint[\"encoder\"]\n",
        "decoder_state_dict = checkpoint[\"decoder\"]\n",
        "\n",
        "# Create the encoder and decoder models with the same architecture as the saved models\n",
        "encoder = EncoderLSTM(len(loaded_fr_i2w), hidden_size).to(device)\n",
        "# attn = Attention(hidden_size,\"concat\")\n",
        "decoder = LuongDecoder(hidden_size,len(loaded_en_i2w),attn).to(device)\n",
        "\n",
        "# Load the state dictionaries into the models\n",
        "encoder.load_state_dict(encoder_state_dict)\n",
        "decoder.load_state_dict(decoder_state_dict)\n",
        "\n",
        "# Set the models to evaluation mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n"
      ],
      "metadata": {
        "id": "nkQvy0e7A0fP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdf3113-5afc-4c5c-e0bf-c7984ac54e77"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LuongDecoder(\n",
              "  (attention): Attention(\n",
              "    (fc): Linear(in_features=512, out_features=512, bias=False)\n",
              "  )\n",
              "  (embedding): Embedding(45942, 512)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(512, 512)\n",
              "  (classifier): Linear(in_features=1024, out_features=45942, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"en_predicted_sum_test1000.txt\", \"w\") as f:\n",
        "  for idx in range(0,len(fr_inputs)):\n",
        "      h = encoder.init_hidden()\n",
        "      inp = torch.tensor(fr_inputs[idx]).unsqueeze(0).to(device)\n",
        "      encoder_outputs, h = encoder(inp,h)\n",
        "\n",
        "      decoder_input = torch.tensor([loaded_en_w2i['_SOS']],device=device)\n",
        "      decoder_hidden = h\n",
        "      output = []\n",
        "      attentions = []\n",
        "      cnt = 0\n",
        "      while True:\n",
        "          decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "          _, top_index = decoder_output.topk(2)\n",
        "          decoder_input = torch.tensor([top_index[0][1].item()],device=device)\n",
        "          #If the decoder output is the End Of Sentence token, stop decoding process\n",
        "          if top_index[0][1].item() == loaded_fr_w2i[\"_EOS\"] or cnt >=25:\n",
        "              break\n",
        "          output.append(top_index[0][1].item())\n",
        "          attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
        "          cnt+=1\n",
        "\n",
        "      summary = ' '.join([loaded_en_i2w[x] for x in output])\n",
        "      print(summary)\n",
        "      f.write(summary + \"\\n\")\n"
      ],
      "metadata": {
        "id": "B0wJFZKR0nEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('en_predicted_test1000_lstm.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    lines = [line.strip() for line in lines]  # Remove trailing newline characters\n",
        "print(lines[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEGNNI4VBwaZ",
        "outputId": "d678cbaf-79d0-4838-8d66-956f0fb856f8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in paris of a simple term are now department , is a simple term , where he was the victim . the government . .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieHJ9Jy7VopR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}